#!/usr/bin/env python
# coding: utf-8

# <h1>lab 01</h1>

# In[5]:


get_ipython().system('pip install requests lxml beautifulsoup4')


# In[6]:


import warnings
warnings.filterwarnings("ignore")


# In[7]:


import requests
from bs4 import BeautifulSoup

from urllib.request import Request, urlopen
import urllib
import urllib.error


# In[8]:


user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'
headers={'user-agent':user_agent}


# In[9]:


param = {
        "view_op": "view_org",                       # author results
        "org": '8607118205373147890',                # organization ID
        "hl": "en",                                  # language  
}

url='https://scholar.google.com/citations?'

try:
    reqest = requests.get(url,headers=headers, params=param)
except urllib.error.HTTPError as e:

    # Return code error (e.g. 404, 501, ...)
    # ...
    print('HTTPError: {}'.format(e.code))

except urllib.error.URLError as e:

    # Not an HTTP-specific error (e.g. connection refused)
    # ...
    print('URLError: {}'.format(e.reason))
else:
    # 200
    # ...
    print('The requested page is rendered successfully: the response status is good')


# In[10]:


def google_citation_by_university(org='8607118205373147890')->BeautifulSoup:

    url = 'https://scholar.google.com/citations?view_op=view_org&hl=en&org=' + org
    reqest = Request(url,headers=headers)
    page = urlopen(reqest)
    page_cont = BeautifulSoup(page, "lxml")
    return page_cont


ORG= '8607118205373147890'
univ_page= google_citation_by_university(ORG)
print(univ_page)


# In[11]:


div = univ_page.find_all(class_="gs_ai_name")
for element in div:
    print(element.prettify())


# In[12]:


researchers =univ_page.find_all(class_="gsc_1usr")

for researcher in researchers:
    name = researcher.find(class_="gs_ai_name")
    if name:
        name = name.get_text().strip()
    else:
        name = "Name not found"
    cby = researcher.find(class_="gs_ai_cby")
    if cby:
        cby = cby.get_text().strip()
    else:
        cby = "Citations not found"
    fields_of_interest = researcher.find_all(class_="gs_ai_one_int")
    if fields_of_interest:
        fields_of_interest = ', '.join([item.get_text().strip() for item in fields_of_interest])
    else:
        fields_of_interest = "Fields of interest not found"
    print(f"Name: {name}")
    print(cby)
    print(f"Fields of interest: {fields_of_interest}")
    print("="*30)




